{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43180034",
   "metadata": {},
   "source": [
    "## Predict Expected generation \n",
    "Use moving average, seasonal features, lag features, and cyclic encoding for hour of day. use other statistical model as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46558792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import plot_importance\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from prophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a188a7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prophet(df):\n",
    "    '''\n",
    "    Prophet automatically handles seasonality (daily, yearly, etc.) and trends.\n",
    "    We do not need to include engineered features like lags, rolling averages, or cyclic encodings in the input DataFrame for Prophet.\n",
    "    '''\n",
    "    df['Date'] = pd.to_datetime(df['Date'], format='%d-%b-%y')\n",
    "    prophet_data = df[['Date','Gen']].rename(columns={'Date':'ds','Gen':'y'})\n",
    "    prophet = Prophet(daily_seasonality=True, yearly_seasonality=True)\n",
    "    prophet.fit(prophet_data)\n",
    "    forecast = prophet.predict(prophet_data)\n",
    "\n",
    "    df['prophet_pred'] = forecast['yhat']  # seasonality + trend baseline\n",
    "    df['residual'] = df['Gen'] - df['prophet_pred']\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17da695e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_xgboost(df):\n",
    "    from xgboost import XGBRegressor\n",
    "    \n",
    "    res_features = ['Season_1','Season_2','Season_3','Season_4', 'POD_Night','POD_Morning','POD_Afternoon','POD_Evening','is_weekend','P/OP', 'is_vacation']\n",
    "    X = df[res_features]\n",
    "    y = df['residual']\n",
    "    # y = df['Gen']\n",
    "\n",
    "    # test-train split\n",
    "    split_index = int(len(df) * 0.8)\n",
    "    X_train, X_test = X.iloc[:split_index], X.iloc[split_index:] \n",
    "    y_train, y_test = y.iloc[:split_index], y.iloc[split_index:]\n",
    "\n",
    "    reg = XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        learning_rate=0.05,\n",
    "        n_estimators=500\n",
    "    )\n",
    "\n",
    "    reg.fit(X_train, y_train)\n",
    "    df.loc[X_test.index, 'xgb_pred'] = reg.predict(X_test)\n",
    "    df['final_pred'] = df['prophet_pred'] + df['xgb_pred']\n",
    "    # clip negative predictions to zero\n",
    "    df['final_pred'] = df['final_pred'].clip(lower=0)\n",
    "\n",
    "    # find accuracy for XGBoost residual model\n",
    "    from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "    mae = mean_absolute_error(df.loc[X_test.index, 'Gen'], df.loc[X_test.index, 'final_pred'])\n",
    "    print(f\"MAE: {mae}\")\n",
    "    \n",
    "    return df, reg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce8d2e7",
   "metadata": {},
   "source": [
    "## Predict for next 5 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798bdbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prediction_pipeline(df):\n",
    "    df_prophet = run_prophet(df)\n",
    "    df_xgb, reg_xgb = run_xgboost(df_prophet)\n",
    "\n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plot_importance(reg_xgb, ax=plt.gca())\n",
    "    plt.title(\"Feature Importance\")\n",
    "    plt.show()\n",
    "\n",
    "    # Create future dates (hourly for 5 years)\n",
    "    # start from 1 january 2026\n",
    "    future_dates = pd.date_range(\n",
    "        start=pd.Timestamp('2026-01-01 00:00:00'),\n",
    "        end=pd.Timestamp('2026-01-01 00:00:00') + pd.DateOffset(years=5),\n",
    "        freq='h'\n",
    "    )\n",
    "    \n",
    "    future_df = pd.DataFrame({'Date': future_dates})\n",
    "    future_df['Month'] = future_df['Date'].dt.month\n",
    "    future_df['Season'] = future_df['Month'].apply(lambda x: (x%12 + 3)//3)\n",
    "    season_dummies = pd.get_dummies(future_df['Season'], dtype=int, prefix='Season')\n",
    "    future_df = pd.concat([future_df, season_dummies], axis=1)\n",
    "    future_df.drop(columns=['Month', 'Season'], inplace=True)  # drop intermediate columns\n",
    "\n",
    "    # Add required features (example, adjust as needed)\n",
    "    future_df['HE'] = future_df['Date'].dt.hour\n",
    "    future_df['Period_of_Day'] = pd.cut(future_df['HE'], bins=[0, 6, 12, 18, 24], labels=['Night', 'Morning', 'Afternoon', 'Evening'], right=False)\n",
    "    pod_dummies = pd.get_dummies(future_df['Period_of_Day'], dtype=int, prefix='POD')\n",
    "    future_df = pd.concat([future_df, pod_dummies], axis=1)\n",
    "    future_df.drop(columns=['Period_of_Day'], inplace=True)\n",
    "\n",
    "    # NERC holidays: New Year's Day, Memorial Day, Labor Day, Thanksgiving, and Christmas\n",
    "    # add vacation indicator\n",
    "    future_df['is_vacation'] = future_df['Date'].apply(\n",
    "        lambda x: 1 if (x.month == 1 and x.day == 1) or\n",
    "                         (x.month == 5 and x.day >= 25 and x.day <= 31 and x.weekday() == 0) or\n",
    "                         (x.month == 9 and x.day >= 1 and x.day <= 7 and x.weekday() == 0) or\n",
    "                         (x.month == 11 and x.month == 11 and x.day >= 22 and x.day <= 28 and x.weekday() == 3) or\n",
    "                         (x.month == 12 and x.day == 25) else 0\n",
    "    )\n",
    "    \n",
    "    # Peak hours 0 = off-peak, 1 = peak\n",
    "    # Peak (P) hours = Mon-Fri, HE 7-22 excl NERC holidays\n",
    "    future_df['P/OP'] = future_df.apply(\n",
    "        lambda row: 1 if (row['Date'].weekday() < 5 and 7 <= row['Date'].hour <= 22 and row['is_vacation'] == 0) else 0,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    future_df['day_of_week'] = future_df['Date'].dt.dayofweek\n",
    "    future_df['is_weekend'] = future_df['day_of_week'].isin([5,6]).astype(int)\n",
    "    \n",
    "\n",
    "    # use Prophet to predict baseline generation\n",
    "    prophet_data = future_df[['Date']].rename(columns={'Date':'ds'})\n",
    "    forecast_future = Prophet(daily_seasonality=True, yearly_seasonality=True).fit(\n",
    "        df[['Date','Gen']].rename(columns={'Date':'ds','Gen':'y'})\n",
    "    ).predict(prophet_data)\n",
    "    future_df['prophet_pred'] = forecast_future['yhat']\n",
    "\n",
    "    # use XGBoost to predict residuals\n",
    "    res_features = ['Season_1','Season_2','Season_3','Season_4', 'POD_Night','POD_Morning','POD_Afternoon','POD_Evening','is_weekend','P/OP', 'is_vacation']\n",
    "    X_future = future_df[res_features]\n",
    "    future_df['xgb_pred'] = reg_xgb.predict(X_future)\n",
    "    future_df['final_pred'] = future_df['prophet_pred'] + future_df['xgb_pred']\n",
    "    # clip negative predictions to zero\n",
    "    future_df['final_pred'] = future_df['final_pred'].clip(lower=0)\n",
    "    return future_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a738294c",
   "metadata": {},
   "source": [
    "Expected generation (by month, peak and off-peak periods)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb7df44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_predictions(prediction, data_dir):\n",
    "    prediction['Date'] = pd.to_datetime(prediction['Date'])\n",
    "    prediction['Year'] = prediction['Date'].dt.year\n",
    "    prediction['Month'] = prediction['Date'].dt.month\n",
    "\n",
    "    # peak mask: Mon-Fri HE 7-22, exclude vacations if the flag exists\n",
    "    if 'is_vacation' in prediction.columns:\n",
    "        peak_mask = (\n",
    "            (prediction['Date'].dt.weekday < 5) &\n",
    "            (prediction['Date'].dt.hour >= 7) &\n",
    "            (prediction['Date'].dt.hour <= 22) &\n",
    "            (prediction['is_vacation'] == 0)\n",
    "        )\n",
    "    else:\n",
    "        peak_mask = (\n",
    "            (prediction['Date'].dt.weekday < 5) &\n",
    "            (prediction['Date'].dt.hour >= 7) &\n",
    "            (prediction['Date'].dt.hour <= 22)\n",
    "        )\n",
    "\n",
    "    # sum final_pred separately for peak and off-peak, then join into two columns\n",
    "    peak = prediction.loc[peak_mask].groupby(['Year', 'Month'])['final_pred'].sum().rename('Peak')\n",
    "    off_peak = prediction.loc[~peak_mask].groupby(['Year', 'Month'])['final_pred'].sum().rename('Off-Peak')\n",
    "\n",
    "    agg_prediction = pd.concat([peak, off_peak], axis=1).fillna(0).reset_index()\n",
    "\n",
    "    agg_prediction.to_csv(data_dir + \"/CAISO-Future-Predictions-Aggregated.csv\", index=False)\n",
    "    return agg_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bdbb0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m data_dir = \u001b[33m\"\u001b[39m\u001b[33m../data\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m caiso_historical_df = \u001b[43mpd\u001b[49m.read_csv(data_dir + \u001b[33m\"\u001b[39m\u001b[33m/CAISO-Historical-Data.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m prediction = run_prediction_pipeline(caiso_historical_df)\n\u001b[32m      4\u001b[39m prediction.to_csv(data_dir + \u001b[33m\"\u001b[39m\u001b[33m/CAISO-Future-Predictions.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "data_dir = \"../data\"\n",
    "caiso_historical_df = pd.read_csv(data_dir + \"/CAISO-Historical-Data.csv\")\n",
    "prediction = run_prediction_pipeline(caiso_historical_df)\n",
    "prediction.to_csv(data_dir + \"/CAISO-Future-Predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac43d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_prediction = aggregate_predictions(prediction, data_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91c7986",
   "metadata": {},
   "source": [
    "Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da139a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(df_old, df_new):\n",
    "    plt.figure(figsize=(14,6))\n",
    "    plt.plot(df_old['Date'], df_old['Gen'], label='Historical Generation', alpha=0.5)\n",
    "    plt.plot(df_new['Date'], df_new['final_pred'], label='Predicted Generation', alpha=0.7)\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Generation')\n",
    "    plt.title('Historical vs Predicted Generation')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0fd1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results_by_year(old_df, new_df, old_year, new_year):\n",
    "    \"\"\"\n",
    "    Plot historical and predicted generation for a specific year as overlapping line charts with smoothed trendlines.\n",
    "    X axis shows months only (Jan, Feb, ... Dec).\n",
    "    \"\"\"\n",
    "    from scipy.interpolate import make_interp_spline\n",
    "\n",
    "    old_df['Date'] = pd.to_datetime(old_df['Date'])\n",
    "    new_df['Date'] = pd.to_datetime(new_df['Date'])\n",
    "    old_mask = old_df['Date'].dt.year == old_year\n",
    "    new_mask = new_df['Date'].dt.year == new_year\n",
    "\n",
    "    # Aggregate by month\n",
    "    old_months = old_df.loc[old_mask].groupby(old_df.loc[old_mask, 'Date'].dt.month)['Gen'].mean()\n",
    "    new_months = new_df.loc[new_mask].groupby(new_df.loc[new_mask, 'Date'].dt.month)['final_pred'].mean()\n",
    "\n",
    "    months = np.array(range(1, 13))\n",
    "    months_smooth = np.linspace(1, 12, 100)\n",
    "\n",
    "    # Spline for smooth trendlines\n",
    "    old_spline = make_interp_spline(months, old_months, k=3)\n",
    "    new_spline = make_interp_spline(months, new_months, k=3)\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    # Line charts\n",
    "    plt.plot(months, old_months, label=f'Historical Generation {old_year}', color='tab:blue', alpha=0.7)\n",
    "    plt.plot(months, new_months, label=f'Predicted Generation {new_year}', color='tab:orange', alpha=0.7)\n",
    "    # Smoothed trendlines\n",
    "    plt.plot(months_smooth, old_spline(months_smooth), color='tab:blue', linestyle='--', label=f'Smooth Trend {old_year}')\n",
    "    plt.plot(months_smooth, new_spline(months_smooth), color='tab:orange', linestyle='--', label=f'Smooth Trend {new_year}')\n",
    "\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('Generation MW/h')\n",
    "    plt.title(f'Historical ({old_year}) vs Predicted ({new_year}) Generation (Monthly Average with Trendline)')\n",
    "    plt.legend()\n",
    "    plt.xticks(ticks=range(1,13), labels=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'])\n",
    "    plt.tight_layout()\n",
    "    # plt.show()\n",
    "    # save plot\n",
    "    plt.savefig(f'Generation_Comparison_{old_year}_vs_{new_year}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c361d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot for all possible years pair\n",
    "# historical year: 2022-2024\n",
    "# predicted year: 2026-2030\n",
    "for hist_year in range(2022, 2025):\n",
    "    for pred_year in range(2026, 2031):\n",
    "        plot_results_by_year(caiso_historical_df, prediction, hist_year, pred_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d143178b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
