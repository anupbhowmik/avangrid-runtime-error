{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72fb9e5a",
   "metadata": {},
   "source": [
    "## Dataset preprocessing\n",
    "This section outlines the steps taken to preprocess the dataset before using any model. Proper preprocessing is crucial for ensuring that the data is clean, consistent, and suitable for analysis.\n",
    "The dataset seems pretty clean, but we performed the following preprocessing steps to ensure data quality:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7f3b17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596dfe41",
   "metadata": {},
   "source": [
    "Replace \"-\" with 0 in the 'Gen' column to handle missing generation values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cfd3a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_gen_column(csv_path):\n",
    "    df = pd.read_csv(csv_path, dtype=str)\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    if \"Gen\" not in df.columns:\n",
    "        print(f\"'Gen' column not found in {csv_path}. Skipping.\")\n",
    "        return\n",
    "\n",
    "    # Replace cells that are exactly \"-\" (allow surrounding spaces) with \"0\"\n",
    "    df[\"Gen\"] = df[\"Gen\"].replace(r\"^\\s*-\\s*$\", \"0\", regex=True)\n",
    "\n",
    "    # Trim whitespace and convert to numeric, non-numeric -> NaN -> fill with 0\n",
    "    df[\"Gen\"] = pd.to_numeric(df[\"Gen\"].str.strip(), errors=\"coerce\").fillna(0)\n",
    "\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(\"Fixed Gen column and saved:\", csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6431d2",
   "metadata": {},
   "source": [
    "**Data Type Conversion**: Convert the relevant columns to numeric types to facilitate mathematical operations and analysis. Remove $ signs and commas before conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "463d480c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dollar(csv_path):\n",
    "    data_hist = pd.read_csv(csv_path)\n",
    "\n",
    "    if 'RT Busbar' not in data_hist.columns or 'RT Hub' not in data_hist.columns or \\\n",
    "       'DA Busbar' not in data_hist.columns or 'DA Hub' not in data_hist.columns or \\\n",
    "       'P/OP' not in data_hist.columns:\n",
    "        print(f\"One or more required columns not found in {csv_path}. Skipping.\")\n",
    "        return\n",
    "\n",
    "    data_hist['RT Busbar'] = data_hist['RT Busbar'].astype(str).str.replace(r'[\\(,]', '-', regex=True)\n",
    "    data_hist['RT Busbar'] = data_hist['RT Busbar'].astype(str).str.replace(r'[\\),]', '', regex=True)\n",
    "    \n",
    "    data_hist['RT Busbar'] = data_hist['RT Busbar'].astype(str).str.replace(r'[\\$,]', '', regex=True)\n",
    "    data_hist['RT Busbar'] = pd.to_numeric(data_hist['RT Busbar'], errors='coerce')\n",
    "    \n",
    "    data_hist['RT Hub'] = data_hist['RT Hub'].astype(str).str.replace(r'[\\$,]', '', regex=True)\n",
    "    data_hist['RT Hub'] = pd.to_numeric(data_hist['RT Hub'], errors='coerce')\n",
    "    \n",
    "    \n",
    "    data_hist['DA Busbar'] = data_hist['DA Busbar'].astype(str).str.replace(r'[\\(,]', '-', regex=True)\n",
    "    data_hist['DA Busbar'] = data_hist['DA Busbar'].astype(str).str.replace(r'[\\),]', '', regex=True)\n",
    "    \n",
    "    data_hist['DA Busbar'] = data_hist['DA Busbar'].astype(str).str.replace(r'[\\$,]', '', regex=True)\n",
    "    data_hist['DA Busbar'] = pd.to_numeric(data_hist['DA Busbar'], errors='coerce')\n",
    "    \n",
    "    data_hist['DA Hub'] = data_hist['DA Hub'].astype(str).str.replace(r'[\\$,]', '', regex=True)\n",
    "    data_hist['DA Hub'] = pd.to_numeric(data_hist['DA Hub'], errors='coerce')\n",
    "    \n",
    "    data_hist['P/OP'] = data_hist['P/OP'].astype(str).str.replace('OP' , '0', regex=True)\n",
    "    data_hist['P/OP'] = data_hist['P/OP'].astype(str).str.replace('P', '1', regex=True)\n",
    "    data_hist['P/OP'] = pd.to_numeric(data_hist['P/OP'], errors='coerce')\n",
    "\n",
    "    data_hist.to_csv(csv_path, index=False)\n",
    "    print(\"Converted dollar columns and saved:\", csv_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60853635",
   "metadata": {},
   "source": [
    "**Handling Missing Values**: Check for any missing values in the dataset. If any found, just drop those rows to maintain data integrity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5538f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_missing_values(csv_path):  \n",
    "    df = pd.read_csv(csv_path)  \n",
    "    df.dropna(inplace=True)\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(\"Dropped rows with missing values and saved:\", csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f288adb2-c1a0-448f-a720-b9429896effe",
   "metadata": {},
   "source": [
    "**Processing forward prices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19a0d13c-365a-4fea-81d6-a02a51234a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_FP(csv_path):\n",
    "    data_hist = pd.read_csv(csv_path)\n",
    "\n",
    "    data_hist['Peak'] = data_hist['Peak'].astype(str).str.replace(r'[\\$,]', '', regex=True)\n",
    "    data_hist['Peak'] = pd.to_numeric(data_hist['Peak'], errors='coerce')\n",
    "    \n",
    "    data_hist['Off Peak'] = data_hist['Off Peak'].astype(str).str.replace(r'[\\$,]', '', regex=True)\n",
    "    data_hist['Off Peak'] = pd.to_numeric(data_hist['Off Peak'], errors='coerce')\n",
    "\n",
    "    data_hist.to_csv(csv_path, index=False)\n",
    "    print(\"Converted dollar columns and saved:\", csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f205f50",
   "metadata": {},
   "source": [
    "Preprocess all the CSV files in the data directory to ensure consistency across datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2b2ca19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted dollar columns and saved: ../data\\CAISO-Forward-Prices.csv\n",
      "Fixed Gen column and saved: ../data\\CAISO-Historical-Data.csv\n",
      "Dropped rows with missing values and saved: ../data\\CAISO-Historical-Data.csv\n",
      "Converted dollar columns and saved: ../data\\CAISO-Historical-Data.csv\n",
      "Converted dollar columns and saved: ../data\\ERCOT-Forward-Prices.csv\n",
      "Fixed Gen column and saved: ../data\\ERCOT-Historical-Data.csv\n",
      "Dropped rows with missing values and saved: ../data\\ERCOT-Historical-Data.csv\n",
      "Converted dollar columns and saved: ../data\\ERCOT-Historical-Data.csv\n",
      "Converted dollar columns and saved: ../data\\MISO-Forward-Prices.csv\n",
      "Fixed Gen column and saved: ../data\\MISO-Historical-Data.csv\n",
      "Dropped rows with missing values and saved: ../data\\MISO-Historical-Data.csv\n",
      "Converted dollar columns and saved: ../data\\MISO-Historical-Data.csv\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"../data\"\n",
    "# traverse all csv files in data directory and apply fixes\n",
    "for filename in os.listdir(data_dir):\n",
    "    csv_path = os.path.join(data_dir, filename)\n",
    "    if '-Forward-Prices.csv' in filename:\n",
    "        process_FP(csv_path)\n",
    "        \n",
    "    elif filename.endswith(\".csv\"):\n",
    "        fix_gen_column(csv_path)\n",
    "        drop_missing_values(csv_path)\n",
    "        convert_dollar(csv_path)\n",
    "        add_features(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5738f6d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80deaa9a-1cf6-496f-98fd-b6717e52ddaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7ba7e9-c8b5-4f75-a30b-f1669b87719b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f2e006-36a9-49b1-839f-8b579760dbd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a0d93f-17a2-473c-9e76-572520eea03f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd759d5e-eb90-4eb5-863e-671f0f1d0fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc27afd5-a1bc-440d-9972-23e45ae6efa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
